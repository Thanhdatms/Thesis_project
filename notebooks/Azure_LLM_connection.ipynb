{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "dY9ORYXHIso5",
        "outputId": "571049ca-b7a6-4b9d-a4f6-311474f7a64d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting azure-ai-inference\n",
            "  Downloading azure_ai_inference-1.0.0b4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting isodate>=0.6.1 (from azure-ai-inference)\n",
            "  Downloading isodate-0.7.2-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting azure-core>=1.30.0 (from azure-ai-inference)\n",
            "  Downloading azure_core-1.31.0-py3-none-any.whl.metadata (39 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from azure-ai-inference) (4.12.2)\n",
            "Requirement already satisfied: requests>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-ai-inference) (2.32.3)\n",
            "Requirement already satisfied: six>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from azure-core>=1.30.0->azure-ai-inference) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-ai-inference) (2024.8.30)\n",
            "Downloading azure_ai_inference-1.0.0b4-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading azure_core-1.31.0-py3-none-any.whl (197 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/197.4 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading isodate-0.7.2-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: isodate, azure-core, azure-ai-inference\n",
            "Successfully installed azure-ai-inference-1.0.0b4 azure-core-1.31.0 isodate-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install azure-ai-inference"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4esdJf8CH5JR"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from azure.ai.inference import ChatCompletionsClient\n",
        "from azure.core.credentials import AzureKeyCredential\n",
        "\n",
        "client = ChatCompletionsClient(\n",
        "    endpoint='',\n",
        "    credential=AzureKeyCredential(''),\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7M6eXalu8-DH"
      },
      "outputs": [],
      "source": [
        "model_info = client.get_model_info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LK131yNH9AdE",
        "outputId": "419951e3-0b25-47de-803a-f346741323df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model name: Meta-Llama-3.1-8B-Instruct\n",
            "Model type: chat-completion\n",
            "Model provider name: Meta\n"
          ]
        }
      ],
      "source": [
        "print(\"Model name:\", model_info.model_name)\n",
        "print(\"Model type:\", model_info.model_type)\n",
        "print(\"Model provider name:\", model_info.model_provider_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXHSKFU19jd_"
      },
      "outputs": [],
      "source": [
        "from azure.ai.inference.models import SystemMessage, UserMessage\n",
        "\n",
        "response = client.complete(\n",
        "    messages=[\n",
        "        SystemMessage(content=\"You are a helpful assistant.\"),\n",
        "        UserMessage(content=\"How many languages are in the world?\"),\n",
        "    ],\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "__exMaR59o7C",
        "outputId": "696804ac-09f6-4a68-921f-04093cef445b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Response: Estimating the exact number of languages in the world is a complex task, as it depends on how one defines a \"language.\" However, based on the most recent estimates, there are approximately 7,097 living languages spoken worldwide.\n",
            "\n",
            "This number comes from Ethnologue, a comprehensive catalog of languages, which is widely considered to be the most authoritative source on language numbers. The count includes languages that are still spoken by living communities, but excludes:\n",
            "\n",
            "1. Dialects (variations of a language that are not mutually intelligible)\n",
            "2. Sign languages\n",
            "3. Pidgins and creoles (simplified languages used for trade or communication between groups)\n",
            "4. Extinct languages (languages that are no longer spoken)\n",
            "5. Constructed languages (artificial languages, such as Esperanto or Klingon)\n",
            "\n",
            "Here's a breakdown of the estimated number of languages:\n",
            "\n",
            "* Living languages: 7,097\n",
            "* Dialects: tens of thousands (many languages have multiple dialects)\n",
            "* Sign languages: approximately 300-400\n",
            "* Pidgins and creoles: around 125\n",
            "* Extinct languages: estimated to be around 350-400\n",
            "* Constructed languages: numerous, but difficult to estimate\n",
            "\n",
            "Keep in mind that language numbers can vary depending on the source and criteria used to define a language. However, 7,097 is the most widely accepted estimate.\n",
            "Model: Meta-Llama-3.1-8B-Instruct\n",
            "Usage:\n",
            "\tPrompt tokens: 29\n",
            "\tTotal tokens: 313\n",
            "\tCompletion tokens: 284\n"
          ]
        }
      ],
      "source": [
        "print(\"Response:\", response.choices[0].message.content)\n",
        "print(\"Model:\", response.model)\n",
        "print(\"Usage:\")\n",
        "print(\"\\tPrompt tokens:\", response.usage.prompt_tokens)\n",
        "print(\"\\tTotal tokens:\", response.usage.total_tokens)\n",
        "print(\"\\tCompletion tokens:\", response.usage.completion_tokens)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lA3DUDFXG4li"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUQ5bDxxGuLp",
        "outputId": "3507519c-ae66-4c78-d60f-6c8ee13668d7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection established\n"
          ]
        }
      ],
      "source": [
        "import psycopg2\n",
        "conn = psycopg2.connect(conn_string)\n",
        "print(\"Connection established\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iHh_Fj7BHctN"
      },
      "outputs": [],
      "source": [
        "cursor = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GGcBm6G4HicP"
      },
      "outputs": [],
      "source": [
        "test = cursor.execute(\"select * from test;\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WvgfaMf7HoL-",
        "outputId": "3a6956bd-7d9a-4713-f41f-1d9f6141d2e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data row = (1, Sample Data)\n"
          ]
        }
      ],
      "source": [
        "rows = cursor.fetchall()\n",
        "\n",
        "# Print all rows\n",
        "\n",
        "for row in rows:\n",
        "    print(\"Data row = (%s, %s)\" %(str(row[0]), str(row[1])))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
